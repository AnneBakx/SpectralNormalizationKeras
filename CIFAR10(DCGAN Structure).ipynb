{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mathlab115/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Dense, Conv2D, Add, Dot, Conv2DTranspose, Activation, Reshape, LeakyReLU, Flatten, BatchNormalization\n",
    "from SpectralNormalizationKeras import DenseSN, ConvSN2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "from keras.utils.generic_utils import Progbar\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for resist GPU memerary\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar100, cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 32, 32, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.concatenate((x_test,x_train))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7e5c17c358>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnF+ITPk3aAKCHnWhsY0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7e5f270898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[9487])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Hyperperemeter\n",
    "BATCHSIZE=64\n",
    "LEARNING_RATE = 0.0002\n",
    "TRAINING_RATIO = 1\n",
    "BETA_1 = 0.5\n",
    "BETA_2 = 0.9\n",
    "EPOCHS = 500\n",
    "BN_MIMENTUM = 0.9\n",
    "BN_EPSILON  = 0.00001\n",
    "SAVE_DIR = 'generated_img_CIFAR10/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def BuildGenerator(summary=True):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(4*4*512, kernel_initializer='glorot_uniform' , input_dim=128))\n",
    "    model.add(Reshape((4,4,512)))\n",
    "    model.add(Conv2DTranspose(256, kernel_size=4, strides=2, padding='same', activation='relu',kernel_initializer='glorot_uniform'))\n",
    "    model.add(BatchNormalization(epsilon=BN_EPSILON, momentum=BN_MIMENTUM))\n",
    "    model.add(Conv2DTranspose(128, kernel_size=4, strides=2, padding='same', activation='relu',kernel_initializer='glorot_uniform'))\n",
    "    model.add(BatchNormalization(epsilon=BN_EPSILON, momentum=BN_MIMENTUM))\n",
    "    model.add(Conv2DTranspose(64,  kernel_size=4, strides=2, padding='same', activation='relu',kernel_initializer='glorot_uniform'))\n",
    "    model.add(BatchNormalization(epsilon=BN_EPSILON, momentum=BN_MIMENTUM))\n",
    "    model.add(Conv2DTranspose(3,   kernel_size=3, strides=1, padding='same', activation='tanh'))\n",
    "    if summary:\n",
    "        print(\"Generator\")\n",
    "        model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def BuildDiscriminator(summary=True, spectral_normalization=True):\n",
    "    if spectral_normalization:\n",
    "        model = Sequential()\n",
    "        model.add(ConvSN2D(64, kernel_size=3, strides=1,kernel_initializer='glorot_uniform', padding='same', input_shape=(32,32,3) ))\n",
    "        model.add(LeakyReLU(0.1))\n",
    "        model.add(ConvSN2D(64, kernel_size=4, strides=2,kernel_initializer='glorot_uniform', padding='same'))\n",
    "        model.add(LeakyReLU(0.1))\n",
    "        model.add(ConvSN2D(128, kernel_size=3, strides=1,kernel_initializer='glorot_uniform', padding='same'))\n",
    "        model.add(LeakyReLU(0.1))\n",
    "        model.add(ConvSN2D(128, kernel_size=4, strides=2,kernel_initializer='glorot_uniform', padding='same'))\n",
    "        model.add(LeakyReLU(0.1))\n",
    "        model.add(ConvSN2D(256, kernel_size=3, strides=1,kernel_initializer='glorot_uniform', padding='same'))\n",
    "        model.add(LeakyReLU(0.1))\n",
    "        model.add(ConvSN2D(256, kernel_size=4, strides=2,kernel_initializer='glorot_uniform', padding='same'))\n",
    "        model.add(LeakyReLU(0.1))\n",
    "        model.add(ConvSN2D(512, kernel_size=3, strides=1,kernel_initializer='glorot_uniform', padding='same'))\n",
    "        model.add(LeakyReLU(0.1))\n",
    "        model.add(Flatten())\n",
    "        model.add(DenseSN(1,kernel_initializer='glorot_uniform'))\n",
    "    else:\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=1,kernel_initializer='glorot_uniform', padding='same', input_shape=(32,32,3) ))\n",
    "        model.add(LeakyReLU(0.1))\n",
    "        model.add(Conv2D(64, kernel_size=4, strides=2,kernel_initializer='glorot_uniform', padding='same'))\n",
    "        model.add(LeakyReLU(0.1))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=1,kernel_initializer='glorot_uniform', padding='same'))\n",
    "        model.add(LeakyReLU(0.1))\n",
    "        model.add(Conv2D(128, kernel_size=4, strides=2,kernel_initializer='glorot_uniform', padding='same'))\n",
    "        model.add(LeakyReLU(0.1))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1,kernel_initializer='glorot_uniform', padding='same'))\n",
    "        model.add(LeakyReLU(0.1))\n",
    "        model.add(Conv2D(256, kernel_size=4, strides=2,kernel_initializer='glorot_uniform', padding='same'))\n",
    "        model.add(LeakyReLU(0.1))\n",
    "        model.add(Conv2D(512, kernel_size=3, strides=1,kernel_initializer='glorot_uniform', padding='same'))\n",
    "        model.add(LeakyReLU(0.1))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1,kernel_initializer='glorot_uniform'))\n",
    "    if summary:\n",
    "        print('Discriminator')\n",
    "        print('Spectral Normalization: {}'.format(spectral_normalization))\n",
    "        model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true*y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 8192)              1056768   \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 8, 8, 256)         2097408   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 16, 16, 128)       524416    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 32, 32, 64)        131136    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 32, 32, 3)         1731      \n",
      "=================================================================\n",
      "Total params: 3,813,251\n",
      "Trainable params: 3,812,355\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Discriminator\n",
      "Spectral Normalization: True\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_s_n2d_1 (ConvSN2D)      (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_s_n2d_2 (ConvSN2D)      (None, 16, 16, 64)        65600     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_s_n2d_3 (ConvSN2D)      (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_s_n2d_4 (ConvSN2D)      (None, 8, 8, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_s_n2d_5 (ConvSN2D)      (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_s_n2d_6 (ConvSN2D)      (None, 4, 4, 256)         1048832   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_s_n2d_7 (ConvSN2D)      (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_sn_1 (DenseSN)         (None, 1)                 8193      \n",
      "=================================================================\n",
      "Total params: 2,935,873\n",
      "Trainable params: 2,935,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = BuildGenerator()\n",
    "discriminator = BuildDiscriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_for_training_generator\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 32, 32, 3)         3813251   \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 1)                 2935873   \n",
      "=================================================================\n",
      "Total params: 6,749,124\n",
      "Trainable params: 6,748,228\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Noise_input_for_training_generator = Input(shape=(128,))\n",
    "Generated_image                    = generator(Noise_input_for_training_generator)\n",
    "Discriminator_output               = discriminator(Generated_image)\n",
    "model_for_training_generator       = Model(Noise_input_for_training_generator, Discriminator_output)\n",
    "print(\"model_for_training_generator\")\n",
    "model_for_training_generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 32, 32, 3)         3813251   \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 1)                 2935873   \n",
      "=================================================================\n",
      "Total params: 6,749,124\n",
      "Trainable params: 3,812,355\n",
      "Non-trainable params: 2,936,769\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.trainable = False\n",
    "model_for_training_generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_for_training_generator.compile(optimizer=Adam(LEARNING_RATE, beta_1=BETA_1, beta_2=BETA_2), loss=wasserstein_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_for_training_discriminator\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_3 (InputLayer)             (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_2 (InputLayer)             (None, 32, 32, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)        (None, 32, 32, 3)     3813251     input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)        (None, 1)             2935873     input_2[0][0]                    \n",
      "                                                                   sequential_1[2][0]               \n",
      "====================================================================================================\n",
      "Total params: 6,749,124\n",
      "Trainable params: 2,935,873\n",
      "Non-trainable params: 3,813,251\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Real_image                             = Input(shape=(32,32,3))\n",
    "Noise_input_for_training_discriminator = Input(shape=(128,))\n",
    "Fake_image                             = generator(Noise_input_for_training_discriminator)\n",
    "Discriminator_output_for_real          = discriminator(Real_image)\n",
    "Discriminator_output_for_fake          = discriminator(Fake_image)\n",
    "\n",
    "model_for_training_discriminator       = Model([Real_image,\n",
    "                                                Noise_input_for_training_discriminator],\n",
    "                                               [Discriminator_output_for_real,\n",
    "                                                Discriminator_output_for_fake])\n",
    "print(\"model_for_training_discriminator\")\n",
    "generator.trainable = False\n",
    "discriminator.trainable = True\n",
    "model_for_training_discriminator.compile(optimizer=Adam(LEARNING_RATE, beta_1=BETA_1, beta_2=BETA_2), loss=[wasserstein_loss, wasserstein_loss])\n",
    "model_for_training_discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real_y = np.ones((BATCHSIZE, 1), dtype=np.float32)\n",
    "fake_y = -real_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X/255*2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7e3c31d7b8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7e442248d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow((X[8787]+1)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 65.16824507713318\n",
      "32/64 [==============>...............] - ETA: 0s303852.484375\n",
      "32/64 [==============>...............] - ETA: 0s-303852.5\n",
      "wasserstein_loss: -0.015625\n",
      "plot generated_image\n",
      "epoch 2 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 62.542468309402466\n",
      "32/64 [==============>...............] - ETA: 0s28137.59375\n",
      "32/64 [==============>...............] - ETA: 0s-28137.58984375\n",
      "wasserstein_loss: 0.00390625\n",
      "plot generated_image\n",
      "epoch 3 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 63.02089309692383\n",
      "32/64 [==============>...............] - ETA: 0s-20227.693359375\n",
      "32/64 [==============>...............] - ETA: 0s20227.6904296875\n",
      "wasserstein_loss: -0.0029296875\n",
      "plot generated_image\n",
      "epoch 4 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 62.636170864105225\n",
      "32/64 [==============>...............] - ETA: 0s308.4568176269531\n",
      "32/64 [==============>...............] - ETA: 0s-308.45680236816406\n",
      "wasserstein_loss: 1.52587890625e-05\n",
      "plot generated_image\n",
      "epoch 5 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 62.65177249908447\n",
      "32/64 [==============>...............] - ETA: 0s9.125412940979004\n",
      "32/64 [==============>...............] - ETA: 0s-9.125412940979004\n",
      "wasserstein_loss: 0.0\n",
      "plot generated_image\n",
      "epoch 6 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 62.981797218322754\n",
      "32/64 [==============>...............] - ETA: 0s139.82650756835938\n",
      "32/64 [==============>...............] - ETA: 0s-139.82653427124023\n",
      "wasserstein_loss: -2.6702880859375e-05\n",
      "plot generated_image\n",
      "epoch 7 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 62.47413969039917\n",
      "32/64 [==============>...............] - ETA: 0s-12049.90087890625\n",
      "32/64 [==============>...............] - ETA: 0s12049.900390625\n",
      "wasserstein_loss: -0.00048828125\n",
      "plot generated_image\n",
      "epoch 8 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 62.5222864151001\n",
      "32/64 [==============>...............] - ETA: 0s782.3915405273438\n",
      "32/64 [==============>...............] - ETA: 0s-782.3914184570312\n",
      "wasserstein_loss: 0.0001220703125\n",
      "plot generated_image\n",
      "epoch 9 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 62.781840801239014\n",
      "32/64 [==============>...............] - ETA: 0s-20925.677734375\n",
      "32/64 [==============>...............] - ETA: 0s20925.677734375\n",
      "wasserstein_loss: 0.0\n",
      "plot generated_image\n",
      "epoch 10 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 62.919121980667114\n",
      "32/64 [==============>...............] - ETA: 0s25513.857421875\n",
      "32/64 [==============>...............] - ETA: 0s-25513.8525390625\n",
      "wasserstein_loss: 0.0048828125\n",
      "plot generated_image\n",
      "epoch 11 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 62.64396548271179\n",
      "32/64 [==============>...............] - ETA: 0s4405.85546875\n",
      "32/64 [==============>...............] - ETA: 0s-4405.856201171875\n",
      "wasserstein_loss: -0.000732421875\n",
      "plot generated_image\n",
      "epoch 12 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 62.605042695999146\n",
      "32/64 [==============>...............] - ETA: 0s-2156.38330078125\n",
      "32/64 [==============>...............] - ETA: 0s2156.3836669921875\n",
      "wasserstein_loss: 0.0003662109375\n",
      "plot generated_image\n",
      "epoch 13 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 62.79693365097046\n",
      "32/64 [==============>...............] - ETA: 0s-511.8352966308594\n",
      "32/64 [==============>...............] - ETA: 0s511.8352355957031\n",
      "wasserstein_loss: -6.103515625e-05\n",
      "plot generated_image\n",
      "epoch 14 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 63.34187030792236\n",
      "32/64 [==============>...............] - ETA: 0s5496.573486328125\n",
      "32/64 [==============>...............] - ETA: 0s-5496.573486328125\n",
      "wasserstein_loss: 0.0\n",
      "plot generated_image\n",
      "epoch 15 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 63.405155420303345\n",
      "32/64 [==============>...............] - ETA: 0s38379.87890625\n",
      "32/64 [==============>...............] - ETA: 0s-38379.8828125\n",
      "wasserstein_loss: -0.00390625\n",
      "plot generated_image\n",
      "epoch 16 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 63.04680347442627\n",
      "32/64 [==============>...............] - ETA: 0s-940.5608825683594\n",
      "32/64 [==============>...............] - ETA: 0s940.5604858398438\n",
      "wasserstein_loss: -0.000396728515625\n",
      "plot generated_image\n",
      "epoch 17 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 62.74458956718445\n",
      "32/64 [==============>...............] - ETA: 0s1367.2808837890625\n",
      "32/64 [==============>...............] - ETA: 0s-1367.28076171875\n",
      "wasserstein_loss: 0.0001220703125\n",
      "plot generated_image\n",
      "epoch 18 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 62.760178565979004\n",
      "32/64 [==============>...............] - ETA: 0s22210.8994140625\n",
      "32/64 [==============>...............] - ETA: 0s-22210.9013671875\n",
      "wasserstein_loss: -0.001953125\n",
      "plot generated_image\n",
      "epoch 19 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 62.38350868225098\n",
      "32/64 [==============>...............] - ETA: 0s24722.587890625\n",
      "32/64 [==============>...............] - ETA: 0s-24722.5849609375\n",
      "wasserstein_loss: 0.0029296875\n",
      "plot generated_image\n",
      "epoch 20 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 62.8512499332428\n",
      "32/64 [==============>...............] - ETA: 0s10135.951171875\n",
      "32/64 [==============>...............] - ETA: 0s-10135.95166015625\n",
      "wasserstein_loss: -0.00048828125\n",
      "plot generated_image\n",
      "epoch 21 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 62.63522410392761\n",
      "32/64 [==============>...............] - ETA: 0s-14744.8076171875\n",
      "32/64 [==============>...............] - ETA: 0s14744.8125\n",
      "wasserstein_loss: 0.0048828125\n",
      "plot generated_image\n",
      "epoch 22 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 62.7241644859314\n",
      "32/64 [==============>...............] - ETA: 0s-6087.533203125\n",
      "32/64 [==============>...............] - ETA: 0s6087.53173828125\n",
      "wasserstein_loss: -0.00146484375\n",
      "plot generated_image\n",
      "epoch 23 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 62.653950452804565\n",
      "32/64 [==============>...............] - ETA: 0s19459.2529296875\n",
      "32/64 [==============>...............] - ETA: 0s-19459.25390625\n",
      "wasserstein_loss: -0.0009765625\n",
      "plot generated_image\n",
      "epoch 24 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 62.43121528625488\n",
      "32/64 [==============>...............] - ETA: 0s-1778.4280395507812\n",
      "32/64 [==============>...............] - ETA: 0s1778.4282836914062\n",
      "wasserstein_loss: 0.000244140625\n",
      "plot generated_image\n",
      "epoch 25 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 62.58331632614136\n",
      "32/64 [==============>...............] - ETA: 0s-22660.49609375\n",
      "32/64 [==============>...............] - ETA: 0s22660.4951171875\n",
      "wasserstein_loss: -0.0009765625\n",
      "plot generated_image\n",
      "epoch 26 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 62.87738633155823\n",
      "32/64 [==============>...............] - ETA: 0s-186330.421875\n",
      "32/64 [==============>...............] - ETA: 0s186330.453125\n",
      "wasserstein_loss: 0.03125\n",
      "plot generated_image\n",
      "epoch 27 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 62.7533974647522\n",
      "32/64 [==============>...............] - ETA: 0s-5970.688720703125\n",
      "32/64 [==============>...............] - ETA: 0s5970.688720703125\n",
      "wasserstein_loss: 0.0\n",
      "plot generated_image\n",
      "epoch 28 of 500\n",
      "number of batches: 937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 62.77288198471069\n",
      "32/64 [==============>...............] - ETA: 0s-18523.3408203125\n",
      "32/64 [==============>...............] - ETA: 0s18523.341796875\n",
      "wasserstein_loss: 0.0009765625\n",
      "plot generated_image\n",
      "epoch 29 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 62.662081718444824\n",
      "32/64 [==============>...............] - ETA: 0s151639.390625\n",
      "32/64 [==============>...............] - ETA: 0s-151639.40625\n",
      "wasserstein_loss: -0.015625\n",
      "plot generated_image\n",
      "epoch 30 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 62.56993389129639\n",
      "32/64 [==============>...............] - ETA: 0s24842.0126953125\n",
      "32/64 [==============>...............] - ETA: 0s-24842.0185546875\n",
      "wasserstein_loss: -0.005859375\n",
      "plot generated_image\n",
      "epoch 31 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 116.5783371925354\n",
      "32/64 [==============>...............] - ETA: 0s137914.578125\n",
      "32/64 [==============>...............] - ETA: 0s-137914.546875\n",
      "wasserstein_loss: 0.03125\n",
      "plot generated_image\n",
      "epoch 32 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 142.68855357170105\n",
      "32/64 [==============>...............] - ETA: 0s461193.390625\n",
      "32/64 [==============>...............] - ETA: 0s-461193.4375\n",
      "wasserstein_loss: -0.046875\n",
      "plot generated_image\n",
      "epoch 33 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 142.94787549972534\n",
      "32/64 [==============>...............] - ETA: 0s12845.04833984375\n",
      "32/64 [==============>...............] - ETA: 0s-12845.04833984375\n",
      "wasserstein_loss: 0.0\n",
      "plot generated_image\n",
      "epoch 34 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.16778111457825\n",
      "32/64 [==============>...............] - ETA: 0s716.3975830078125\n",
      "32/64 [==============>...............] - ETA: 0s-716.3974609375\n",
      "wasserstein_loss: 0.0001220703125\n",
      "plot generated_image\n",
      "epoch 35 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.130028963089\n",
      "32/64 [==============>...............] - ETA: 0s20542.46875\n",
      "32/64 [==============>...............] - ETA: 0s-20542.46875\n",
      "wasserstein_loss: 0.0\n",
      "plot generated_image\n",
      "epoch 36 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.01438903808594\n",
      "32/64 [==============>...............] - ETA: 0s741.1277313232422\n",
      "32/64 [==============>...............] - ETA: 0s-741.1276702880859\n",
      "wasserstein_loss: 6.103515625e-05\n",
      "plot generated_image\n",
      "epoch 37 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.11650466918945\n",
      "32/64 [==============>...............] - ETA: 0s706.7819213867188\n",
      "32/64 [==============>...............] - ETA: 0s-706.781982421875\n",
      "wasserstein_loss: -6.103515625e-05\n",
      "plot generated_image\n",
      "epoch 38 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.20141768455505\n",
      "32/64 [==============>...............] - ETA: 0s128898.65625\n",
      "32/64 [==============>...............] - ETA: 0s-128898.6640625\n",
      "wasserstein_loss: -0.0078125\n",
      "plot generated_image\n",
      "epoch 39 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.19447422027588\n",
      "32/64 [==============>...............] - ETA: 0s91.67986679077148\n",
      "32/64 [==============>...............] - ETA: 0s-91.67985916137695\n",
      "wasserstein_loss: 7.62939453125e-06\n",
      "plot generated_image\n",
      "epoch 40 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.38030195236206\n",
      "32/64 [==============>...............] - ETA: 0s10979.525390625\n",
      "32/64 [==============>...............] - ETA: 0s-10979.5244140625\n",
      "wasserstein_loss: 0.0009765625\n",
      "plot generated_image\n",
      "epoch 41 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.24672198295593\n",
      "32/64 [==============>...............] - ETA: 0s-179379.2421875\n",
      "32/64 [==============>...............] - ETA: 0s179379.2421875\n",
      "wasserstein_loss: 0.0\n",
      "plot generated_image\n",
      "epoch 42 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.40139651298523\n",
      "32/64 [==============>...............] - ETA: 0s1783.0843811035156\n",
      "32/64 [==============>...............] - ETA: 0s-1783.0848693847656\n",
      "wasserstein_loss: -0.00048828125\n",
      "plot generated_image\n",
      "epoch 43 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.28142595291138\n",
      "32/64 [==============>...............] - ETA: 0s70652.69140625\n",
      "32/64 [==============>...............] - ETA: 0s-70652.6796875\n",
      "wasserstein_loss: 0.01171875\n",
      "plot generated_image\n",
      "epoch 44 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.22811913490295\n",
      "32/64 [==============>...............] - ETA: 0s52606.919921875\n",
      "32/64 [==============>...............] - ETA: 0s-52606.923828125\n",
      "wasserstein_loss: -0.00390625\n",
      "plot generated_image\n",
      "epoch 45 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.0456473827362\n",
      "32/64 [==============>...............] - ETA: 0s2902.283935546875\n",
      "32/64 [==============>...............] - ETA: 0s-2902.283935546875\n",
      "wasserstein_loss: 0.0\n",
      "plot generated_image\n",
      "epoch 46 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.41815614700317\n",
      "32/64 [==============>...............] - ETA: 0s314701.28125\n",
      "32/64 [==============>...............] - ETA: 0s-314701.15625\n",
      "wasserstein_loss: 0.125\n",
      "plot generated_image\n",
      "epoch 47 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.3633599281311\n",
      "32/64 [==============>...............] - ETA: 0s16425.404296875\n",
      "32/64 [==============>...............] - ETA: 0s-16425.404296875\n",
      "wasserstein_loss: 0.0\n",
      "plot generated_image\n",
      "epoch 48 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.09456491470337\n",
      "32/64 [==============>...............] - ETA: 0s19338.205078125\n",
      "32/64 [==============>...............] - ETA: 0s-19338.2060546875\n",
      "wasserstein_loss: -0.0009765625\n",
      "plot generated_image\n",
      "epoch 49 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.4356973171234\n",
      "32/64 [==============>...............] - ETA: 0s1200212.625\n",
      "32/64 [==============>...............] - ETA: 0s-1200212.5625\n",
      "wasserstein_loss: 0.0625\n",
      "plot generated_image\n",
      "epoch 50 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.32785987854004\n",
      "32/64 [==============>...............] - ETA: 0s17681.380859375\n",
      "32/64 [==============>...............] - ETA: 0s-17681.3818359375\n",
      "wasserstein_loss: -0.0009765625\n",
      "plot generated_image\n",
      "epoch 51 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.17687368392944\n",
      "32/64 [==============>...............] - ETA: 0s1083.471923828125\n",
      "32/64 [==============>...............] - ETA: 0s-1083.4719848632812\n",
      "wasserstein_loss: -6.103515625e-05\n",
      "plot generated_image\n",
      "epoch 52 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.34113025665283\n",
      "32/64 [==============>...............] - ETA: 0s-163.92031860351562\n",
      "32/64 [==============>...............] - ETA: 0s163.92041015625\n",
      "wasserstein_loss: 9.1552734375e-05\n",
      "plot generated_image\n",
      "epoch 53 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.1333510875702\n",
      "32/64 [==============>...............] - ETA: 0s-3652.2547607421875\n",
      "32/64 [==============>...............] - ETA: 0s3652.25439453125\n",
      "wasserstein_loss: -0.0003662109375\n",
      "plot generated_image\n",
      "epoch 54 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.2648549079895\n",
      "32/64 [==============>...............] - ETA: 0s23846.7197265625\n",
      "32/64 [==============>...............] - ETA: 0s-23846.720703125\n",
      "wasserstein_loss: -0.0009765625\n",
      "plot generated_image\n",
      "epoch 55 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.43644404411316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/64 [==============>...............] - ETA: 0s-1160.9150695800781\n",
      "32/64 [==============>...............] - ETA: 0s1160.9150390625\n",
      "wasserstein_loss: -3.0517578125e-05\n",
      "plot generated_image\n",
      "epoch 56 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.14479684829712\n",
      "32/64 [==============>...............] - ETA: 0s205704.4765625\n",
      "32/64 [==============>...............] - ETA: 0s-205704.5\n",
      "wasserstein_loss: -0.0234375\n",
      "plot generated_image\n",
      "epoch 57 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.1595184803009\n",
      "32/64 [==============>...............] - ETA: 0s214128.421875\n",
      "32/64 [==============>...............] - ETA: 0s-214128.4375\n",
      "wasserstein_loss: -0.015625\n",
      "plot generated_image\n",
      "epoch 58 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.69402623176575\n",
      "32/64 [==============>...............] - ETA: 0s357473.6875\n",
      "32/64 [==============>...............] - ETA: 0s-357473.6875\n",
      "wasserstein_loss: 0.0\n",
      "plot generated_image\n",
      "epoch 59 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.1689932346344\n",
      "32/64 [==============>...............] - ETA: 0s3030.144775390625\n",
      "32/64 [==============>...............] - ETA: 0s-3030.144775390625\n",
      "wasserstein_loss: 0.0\n",
      "plot generated_image\n",
      "epoch 60 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 142.90121936798096\n",
      "32/64 [==============>...............] - ETA: 0s43717.421875\n",
      "32/64 [==============>...............] - ETA: 0s-43717.4140625\n",
      "wasserstein_loss: 0.0078125\n",
      "plot generated_image\n",
      "epoch 61 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.40205717086792\n",
      "32/64 [==============>...............] - ETA: 0s18458.150390625\n",
      "32/64 [==============>...............] - ETA: 0s-18458.1484375\n",
      "wasserstein_loss: 0.001953125\n",
      "plot generated_image\n",
      "epoch 62 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.29782032966614\n",
      "32/64 [==============>...............] - ETA: 0s8434.35986328125\n",
      "32/64 [==============>...............] - ETA: 0s-8434.36181640625\n",
      "wasserstein_loss: -0.001953125\n",
      "plot generated_image\n",
      "epoch 63 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.2476487159729\n",
      "32/64 [==============>...............] - ETA: 0s2583.520751953125\n",
      "32/64 [==============>...............] - ETA: 0s-2583.5205078125\n",
      "wasserstein_loss: 0.000244140625\n",
      "plot generated_image\n",
      "epoch 64 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.11145520210266\n",
      "32/64 [==============>...............] - ETA: 0s1093228.625\n",
      "32/64 [==============>...............] - ETA: 0s-1093228.625\n",
      "wasserstein_loss: 0.0\n",
      "plot generated_image\n",
      "epoch 65 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.30057883262634\n",
      "32/64 [==============>...............] - ETA: 0s5922.743896484375\n",
      "32/64 [==============>...............] - ETA: 0s-5922.74365234375\n",
      "wasserstein_loss: 0.000244140625\n",
      "plot generated_image\n",
      "epoch 66 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.27173256874084\n",
      "32/64 [==============>...............] - ETA: 0s46721.65625\n",
      "32/64 [==============>...............] - ETA: 0s-46721.650390625\n",
      "wasserstein_loss: 0.005859375\n",
      "plot generated_image\n",
      "epoch 67 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.0510015487671\n",
      "32/64 [==============>...............] - ETA: 0s72287.95703125\n",
      "32/64 [==============>...............] - ETA: 0s-72287.9609375\n",
      "wasserstein_loss: -0.00390625\n",
      "plot generated_image\n",
      "epoch 68 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.097674369812\n",
      "32/64 [==============>...............] - ETA: 0s195119.015625\n",
      "32/64 [==============>...............] - ETA: 0s-195119.0390625\n",
      "wasserstein_loss: -0.0234375\n",
      "plot generated_image\n",
      "epoch 69 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.10562801361084\n",
      "32/64 [==============>...............] - ETA: 0s79763.412109375\n",
      "32/64 [==============>...............] - ETA: 0s-79763.390625\n",
      "wasserstein_loss: 0.021484375\n",
      "plot generated_image\n",
      "epoch 70 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.1480643749237\n",
      "32/64 [==============>...............] - ETA: 0s75719.97265625\n",
      "32/64 [==============>...............] - ETA: 0s-75719.96875\n",
      "wasserstein_loss: 0.00390625\n",
      "plot generated_image\n",
      "epoch 71 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.40586709976196\n",
      "32/64 [==============>...............] - ETA: 0s2463.28466796875\n",
      "32/64 [==============>...............] - ETA: 0s-2463.2850341796875\n",
      "wasserstein_loss: -0.0003662109375\n",
      "plot generated_image\n",
      "epoch 72 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.6230444908142\n",
      "32/64 [==============>...............] - ETA: 0s1767.931396484375\n",
      "32/64 [==============>...............] - ETA: 0s-1767.9310607910156\n",
      "wasserstein_loss: 0.000335693359375\n",
      "plot generated_image\n",
      "epoch 73 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.33765983581543\n",
      "32/64 [==============>...............] - ETA: 0s-1995867.25\n",
      "32/64 [==============>...............] - ETA: 0s1995867.375\n",
      "wasserstein_loss: 0.125\n",
      "plot generated_image\n",
      "epoch 74 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.34909963607788\n",
      "32/64 [==============>...............] - ETA: 0s253363.640625\n",
      "32/64 [==============>...............] - ETA: 0s-253363.625\n",
      "wasserstein_loss: 0.015625\n",
      "plot generated_image\n",
      "epoch 75 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.50684595108032\n",
      "32/64 [==============>...............] - ETA: 0s126114.1484375\n",
      "32/64 [==============>...............] - ETA: 0s-126114.15625\n",
      "wasserstein_loss: -0.0078125\n",
      "plot generated_image\n",
      "epoch 76 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.13973212242126\n",
      "32/64 [==============>...............] - ETA: 0s-14083.3173828125\n",
      "32/64 [==============>...............] - ETA: 0s14083.3203125\n",
      "wasserstein_loss: 0.0029296875\n",
      "plot generated_image\n",
      "epoch 77 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.43098282814026\n",
      "32/64 [==============>...............] - ETA: 0s8593.55517578125\n",
      "32/64 [==============>...............] - ETA: 0s-8593.5537109375\n",
      "wasserstein_loss: 0.00146484375\n",
      "plot generated_image\n",
      "epoch 78 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.352520942688\n",
      "32/64 [==============>...............] - ETA: 0s10123.69482421875\n",
      "32/64 [==============>...............] - ETA: 0s-10123.6943359375\n",
      "wasserstein_loss: 0.00048828125\n",
      "plot generated_image\n",
      "epoch 79 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.02869772911072\n",
      "32/64 [==============>...............] - ETA: 0s-141813.23828125\n",
      "32/64 [==============>...............] - ETA: 0s141813.21484375\n",
      "wasserstein_loss: -0.0234375\n",
      "plot generated_image\n",
      "epoch 80 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.6164309978485\n",
      "32/64 [==============>...............] - ETA: 0s2867381.5\n",
      "32/64 [==============>...............] - ETA: 0s-2867382.125\n",
      "wasserstein_loss: -0.625\n",
      "plot generated_image\n",
      "epoch 81 of 500\n",
      "number of batches: 937\n",
      "936/937 [============================>.] - ETA: 0s\n",
      " epoch time: 143.46259713172913\n",
      "32/64 [==============>...............] - ETA: 0s34062.7158203125\n",
      "32/64 [==============>...............] - ETA: 0s-34062.7138671875\n",
      "wasserstein_loss: 0.001953125\n",
      "plot generated_image\n",
      "epoch 82 of 500\n",
      "number of batches: 937\n",
      "869/937 [==========================>...] - ETA: 10s"
     ]
    }
   ],
   "source": [
    "test_noise = np.random.randn(BATCHSIZE, 128)\n",
    "W_loss = []\n",
    "discriminator_loss = []\n",
    "generator_loss = []\n",
    "for epoch in range(EPOCHS):\n",
    "    np.random.shuffle(X)\n",
    "    \n",
    "    print(\"epoch {} of {}\".format(epoch+1, EPOCHS))\n",
    "    num_batches = int(X.shape[0] // BATCHSIZE)\n",
    "    \n",
    "    print(\"number of batches: {}\".format(int(X.shape[0] // (BATCHSIZE))))\n",
    "    \n",
    "    progress_bar = Progbar(target=int(X.shape[0] // (BATCHSIZE * TRAINING_RATIO)))\n",
    "    minibatches_size = BATCHSIZE * TRAINING_RATIO\n",
    "    \n",
    "    start_time = time()\n",
    "    for index in range(int(X.shape[0] // (BATCHSIZE * TRAINING_RATIO))):\n",
    "        progress_bar.update(index)\n",
    "        discriminator_minibatches = X[index * minibatches_size:(index + 1) * minibatches_size]\n",
    "        \n",
    "        for j in range(TRAINING_RATIO):\n",
    "            image_batch = discriminator_minibatches[j * BATCHSIZE : (j + 1) * BATCHSIZE]\n",
    "            noise = np.random.randn(BATCHSIZE, 128).astype(np.float32)\n",
    "            discriminator.trainable = True\n",
    "            generator.trainable = False\n",
    "            discriminator_loss.append(model_for_training_discriminator.train_on_batch([image_batch, noise],\n",
    "                                                                                      [real_y, fake_y]))\n",
    "        discriminator.trainable = False\n",
    "        generator.trainable = True\n",
    "        generator_loss.append(model_for_training_generator.train_on_batch(np.random.randn(BATCHSIZE, 128), real_y))\n",
    "    \n",
    "    print('\\n epoch time: {}'.format(time()-start_time))\n",
    "    \n",
    "    W_real = model_for_training_generator.evaluate(test_noise, real_y)\n",
    "    print(W_real)\n",
    "    W_fake = model_for_training_generator.evaluate(test_noise, fake_y)\n",
    "    print(W_fake)\n",
    "    W_l = W_real+W_fake\n",
    "    print('wasserstein_loss: {}'.format(W_l))\n",
    "    W_loss.append(W_l)\n",
    "    #Generate image\n",
    "    generated_image = generator.predict(test_noise)\n",
    "    generated_image = (generated_image+1)/2\n",
    "    for i in range(4):\n",
    "        new = generated_image[i*4:i*4+4].reshape(32*4,32,3)\n",
    "        if i!=0:\n",
    "            old = np.concatenate((old,new),axis=1)\n",
    "        else:\n",
    "            old = new\n",
    "    print('plot generated_image')\n",
    "    plt.imsave('{}/SN_epoch_{}.png'.format(SAVE_DIR, epoch), old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(W_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
